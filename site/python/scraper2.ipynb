{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import datetime\n",
    "import duckdb\n",
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results(racename, raceyear):\n",
    "    \n",
    "    # Sleep a little\n",
    "    time.sleep(3)\n",
    "\n",
    "    # Set the time and date for the output table\n",
    "    UPDATE_TIMESTAMP = str(datetime.datetime.now())[0:19]\n",
    "\n",
    "    # URLs for race, route and results\n",
    "    URL_PCS_BASE = \"https://www.procyclingstats.com/race/\"\n",
    "    URL_RACE = URL_PCS_BASE + racename + \"/\" + str(raceyear)\n",
    "    URL_ROUTE = URL_RACE + \"/route/\"\n",
    "\n",
    "    print()\n",
    "    print(\"URL_RACE:\", URL_RACE)\n",
    "\n",
    "    # Get soup of the route to check if race is valid; and if so if it is a one day race or a stage race\n",
    "    page = requests.get(URL_ROUTE)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    # Check if link is valid\n",
    "    if soup.title is None or soup.title.text.startswith(\"Page not found\"):\n",
    "        print(\"RACE LINK NOT VALID!\")\n",
    "        return 0\n",
    "    \n",
    "    # List of results needed to scrape\n",
    "    RESULTS_TO_SCRAPE = []\n",
    "\n",
    "    # Find out if the race is a one day race or a stage race\n",
    "    tables = soup.find_all(\"table\")\n",
    "    for table in tables:\n",
    "        headers = table.find(\"thead\").find_all(\"th\")\n",
    "        headers = [header.text.strip() for header in headers]\n",
    "        if \"Date\" in headers:\n",
    "            idx_date = headers.index(\"Date\")\n",
    "            idx_stage = headers.index(\"#\")\n",
    "            idx_distance = headers.index(\"Distance\")\n",
    "            idx_vertical = headers.index(\"Vertical meters\")\n",
    "            rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "\n",
    "            # If rows are found, it is a stage race, otherwise a one day race\n",
    "            if rows:\n",
    "                # Get the stages of the race\n",
    "                for row_num, row in enumerate(rows):                    \n",
    "                    cols = row.find_all(\"td\")\n",
    "                    stage_number = row_num + 1\n",
    "                    stage_date = cols[idx_date].text\n",
    "                    stage_name = cols[idx_stage].text\n",
    "                    stage_distance = cols[idx_distance].text\n",
    "                    stage_vertical = cols[idx_vertical].text\n",
    "                    stage_link = \"https://www.procyclingstats.com/\" + cols[idx_stage].find(\"a\")[\"href\"] if cols[idx_stage].find(\"a\") else None\n",
    "\n",
    "                    if \"Prologue\" in stage_name:\n",
    "                        stage_type = \"Prologue\"\n",
    "                    elif \"ITT\" in stage_name:\n",
    "                        stage_type = \"ITT\"\n",
    "                    elif \"TTT\" in stage_name:\n",
    "                        stage_type = \"TTT\"\n",
    "                    else:\n",
    "                        stage_type = \"Normal stage\"\n",
    "\n",
    "                    # Ignore the final row in the table of all stages\n",
    "                    if stage_name == \"\":\n",
    "                        continue\n",
    "\n",
    "                    RESULTS_TO_SCRAPE.append({\n",
    "                        \"Stage number\": stage_number,\n",
    "                        \"Stage name\": stage_name,\n",
    "                        \"Stage link\": stage_link,\n",
    "                        \"Stage type\": stage_type,\n",
    "                        \"Stage date\": stage_date,\n",
    "                        \"Stage distance\": stage_distance,\n",
    "                        \"Stage vertical meters\": stage_vertical\n",
    "                    })\n",
    "                # Also add GC and perhaps different jerseys to the list of results to get\n",
    "                RESULTS_TO_SCRAPE.append({\n",
    "                    \"Stage number\": 99,\n",
    "                    \"Stage name\": \"GC\",\n",
    "                    \"Stage link\": URL_RACE + \"/gc\",\n",
    "                    \"Stage type\": \"GC\",\n",
    "                    \"Stage date\": \"\",\n",
    "                    \"Stage distance\": \"\",\n",
    "                    \"Stage vertical meters\": \"\"\n",
    "                })     \n",
    "\n",
    "            else:\n",
    "                # If it is a one day race get the race date from the main page of the race\n",
    "                page = requests.get(URL_RACE)\n",
    "                soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "                info_list = soup.find('ul', class_='keyvalueList')\n",
    "                for li in info_list.find_all('li'):\n",
    "                    title_div = li.find('div', class_='title')\n",
    "                    if title_div and 'Startdate:' in title_div.text:\n",
    "                        value_div = li.find('div', class_='value')\n",
    "                        if value_div:\n",
    "                            odr_date = value_div.text.strip()\n",
    "\n",
    "                RESULTS_TO_SCRAPE.append({\n",
    "                    \"Stage number\": 99,\n",
    "                    \"Stage name\": \"Result\",\n",
    "                    \"Stage link\": URL_RACE + \"/result\",\n",
    "                    \"Stage type\": \"Result\",\n",
    "                    \"Stage date\": odr_date,\n",
    "                    \"Stage distance\": \"\",\n",
    "                    \"Stage vertical meters\": \"\"\n",
    "                })     \n",
    "                \n",
    "            break\n",
    "\n",
    "    conn = duckdb.connect()\n",
    "    conn.execute(\"\"\"\n",
    "    CREATE TABLE ScrapedResults (\n",
    "        RaceName            TEXT,\n",
    "        RaceYear            INTEGER,\n",
    "        StageNumber         INTEGER,\n",
    "        StageName           TEXT,\n",
    "        StageType           TEXT,\n",
    "        StageDate           TEXT,\n",
    "        RiderRank           TEXT,\n",
    "        RiderName           TEXT,\n",
    "        TeamName            TEXT,\n",
    "        UCIPoints           TEXT,\n",
    "        PCSPoints           TEXT,\n",
    "        UpdateTimeStamp     TEXT\n",
    "    )\n",
    "    \"\"\")\n",
    "\n",
    "    for r in RESULTS_TO_SCRAPE:\n",
    "        time.sleep(2)\n",
    "        URL_RESULT = r[\"Stage link\"]\n",
    "        STAGE_TYPE = r[\"Stage type\"]\n",
    "        STAGE_NAME = r[\"Stage name\"]\n",
    "        STAGE_DATE = r[\"Stage date\"]\n",
    "        STAGE_NUMBER = r[\"Stage number\"]\n",
    "        print(STAGE_NAME)  \n",
    "        \n",
    "        page = requests.get(URL_RESULT)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "        tables = soup.find_all(\"table\")\n",
    "\n",
    "        if STAGE_TYPE == \"TTT\":\n",
    "            info_list = soup.find('ul', class_='ttt-results')\n",
    "            for li in info_list.find_all(\"li\"):\n",
    "                for di in li.find_all(\"div\"):\n",
    "                    if \"w10\" in di.get(\"class\"):\n",
    "                        li_rank = di.text.strip()\n",
    "                    elif \"w90\" in di.get(\"class\"):\n",
    "                        li_team = di.text.strip()\n",
    "                    elif \"w100\" in di.get(\"class\"):\n",
    "                        table = di.find(\"table\")\n",
    "                        rows = table.find_all(\"tr\")\n",
    "                        for row in rows:\n",
    "                            cols = row.find_all(\"td\")\n",
    "                            li_rider = cols[0].text.strip()\n",
    "                            li_uci = cols[1].text.strip()\n",
    "                            li_pcs = cols[2].text.strip().strip()\n",
    "                            data = [\n",
    "                                racename,\n",
    "                                raceyear,\n",
    "                                STAGE_NUMBER,\n",
    "                                STAGE_NAME,\n",
    "                                STAGE_TYPE,\n",
    "                                STAGE_DATE,\n",
    "                                li_rank,\n",
    "                                li_rider,\n",
    "                                li_team,\n",
    "                                li_uci,\n",
    "                                li_pcs,\n",
    "                                UPDATE_TIMESTAMP\n",
    "                            ]\n",
    "                            conn.executemany(\"INSERT INTO ScrapedResults VALUES (?,?,?,?,?,?,?,?,?,?,?,?)\", [data])\n",
    "\n",
    "            continue\n",
    "\n",
    "        relevant_table_found = False\n",
    "        relevant_table_number = 0\n",
    "        for table_number, table in enumerate(tables):\n",
    "            headers = table.find(\"thead\").find_all(\"th\")\n",
    "            headers = [header.text.strip() for header in headers]     \n",
    "            if STAGE_TYPE == \"Normal stage\":\n",
    "                if \"UCI\" in headers and \"Time won/lost\" not in headers:\n",
    "                    relevant_table_number = table_number\n",
    "                    relevant_table_found = True\n",
    "                    break\n",
    "            elif STAGE_TYPE == \"GC\":\n",
    "                if \"UCI\" in headers and \"Time won/lost\" in headers:\n",
    "                    relevant_table_number = table_number\n",
    "                    relevant_table_found = True\n",
    "                    break\n",
    "            elif STAGE_TYPE == \"ITT\" or STAGE_TYPE == \"Prologue\":\n",
    "                if \"UCI\" in headers and \"Avg\" in headers:\n",
    "                    relevant_table_number = table_number\n",
    "                    relevant_table_found = True\n",
    "                    break\n",
    "            elif STAGE_TYPE == \"TTT\":\n",
    "                pass\n",
    "            elif STAGE_TYPE == \"Result\":\n",
    "                if \"UCI\" in headers and \"Time\" in headers:\n",
    "                    relevant_table_number = table_number\n",
    "                    relevant_table_found = True\n",
    "                    break\n",
    "            \n",
    "        if relevant_table_found == False:\n",
    "            continue\n",
    "\n",
    "        table = tables[relevant_table_number]\n",
    "        headers = table.find(\"thead\").find_all(\"th\")\n",
    "        headers = [header.text.strip() for header in headers]\n",
    "        idx_rank = headers.index(\"Rnk\")\n",
    "        idx_rider = headers.index(\"Rider\")\n",
    "        idx_team = headers.index(\"Team\")\n",
    "        idx_uci = headers.index(\"UCI\")\n",
    "        idx_pcs = headers.index(\"Pnt\")\n",
    "\n",
    "        rows = table.find(\"tbody\").find_all(\"tr\")\n",
    "        for row in rows:\n",
    "            cols = row.find_all(\"td\")\n",
    "            # If the row isn't an actual result row, but a row with info on a relegation, it is removed\n",
    "            if len(cols) < 2:\n",
    "                pass\n",
    "            else:\n",
    "                data = [\n",
    "                    racename,\n",
    "                    raceyear,\n",
    "                    STAGE_NUMBER,\n",
    "                    STAGE_NAME,\n",
    "                    STAGE_TYPE,\n",
    "                    STAGE_DATE,\n",
    "                    cols[idx_rank].text.strip(),\n",
    "                    cols[idx_rider].text.strip(),\n",
    "                    cols[idx_team].text.strip(),\n",
    "                    cols[idx_uci].text.strip(),\n",
    "                    cols[idx_pcs].text.strip(),\n",
    "                    UPDATE_TIMESTAMP\n",
    "                ]\n",
    "\n",
    "            conn.executemany(\"INSERT INTO ScrapedResults VALUES (?,?,?,?,?,?,?,?,?,?,?,?)\", [data])\n",
    "\n",
    "    conn.execute(\"COPY ScrapedResults TO '../data/results_races/results_\" + racename + \"-\" + str(raceyear) + \".csv' (HEADER, DELIMITER ',')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "URL_RACE: https://www.procyclingstats.com/race/cyclassics-hamburg/2025\n",
      "Result\n",
      "\n",
      "URL_RACE: https://www.procyclingstats.com/race/renewi-tour/2025\n",
      "Stage 1\n",
      "Stage 2\n",
      "Stage 3\n",
      "Stage 4\n",
      "Stage 5\n",
      "GC\n",
      "\n",
      "URL_RACE: https://www.procyclingstats.com/race/deutschland-tour/2025\n",
      "Prologue\n",
      "Stage 1\n",
      "Stage 2\n",
      "Stage 3\n",
      "Stage 4\n",
      "GC\n",
      "\n",
      "URL_RACE: https://www.procyclingstats.com/race/vuelta-a-espana/2025\n",
      "Stage 1\n",
      "Stage 2\n",
      "Stage 3\n",
      "Stage 4\n",
      "Stage 5 (TTT)\n",
      "Stage 6\n",
      "Stage 7\n",
      "Stage 8\n",
      "Stage 9\n",
      "Stage 10\n",
      "Stage 11\n",
      "Stage 12\n",
      "Stage 13\n",
      "Stage 14\n",
      "Stage 15\n",
      "Stage 16\n",
      "Stage 17\n",
      "Stage 18 (ITT)\n",
      "Stage 19\n",
      "Stage 20\n",
      "Stage 21\n",
      "GC\n"
     ]
    }
   ],
   "source": [
    "NOW = datetime.datetime.now()\n",
    "FROM = NOW + datetime.timedelta(days = -10)\n",
    "TO = NOW + datetime.timedelta(days = 30)\n",
    "\n",
    "RACES = []\n",
    "with open(\"../data/races.csv\", newline = '') as csvfile:\n",
    "    reader = csv.DictReader(csvfile)\n",
    "    for row in reader:\n",
    "        if datetime.datetime.strptime(row[\"RaceStart\"], \"%Y-%m-%d %H:%M:00\") < NOW and datetime.datetime.strptime(row[\"RaceEnd\"], \"%Y-%m-%d %H:%M:00\") > FROM and datetime.datetime.strptime(row[\"RaceEnd\"], \"%Y-%m-%d %H:%M:00\") < TO:\n",
    "            RACES.append(row[\"RaceName_PCS\"])\n",
    "\n",
    "for race in RACES:\n",
    "    get_results(race, 2025)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
